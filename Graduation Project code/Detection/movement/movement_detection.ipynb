{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils, sys, os, inspect\n",
    "from tensorflow.keras.models import load_model\n",
    "import multiprocessing, threading\n",
    "import tensorflow as tf\n",
    "sys.path.insert(0,\"D:\\\\College\\\\2020\\\\GP\\\\Coding\\\\GP-Code\") \n",
    "\n",
    "from data import DataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.2.4', '2.3.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "keras.__version__, tf.__version__\n",
    "# ('2.2.4', '1.14.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 30, 150, 150, 32)  4736      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 30, 150, 150, 32)  128       \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 30, 150, 150, 32)  0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 30, 148, 148, 32)  9248      \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 30, 148, 148, 32)  128       \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 30, 148, 148, 32)  0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 30, 74, 74, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 30, 74, 74, 64)    18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 30, 74, 74, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 30, 74, 74, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 30, 74, 74, 64)    36928     \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 30, 74, 74, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 30, 74, 74, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 30, 37, 37, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 30, 37, 37, 128)   73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 30, 37, 37, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 30, 37, 37, 128)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 30, 37, 37, 128)   147584    \n",
      "_________________________________________________________________\n",
      "time_distributed_19 (TimeDis (None, 30, 37, 37, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_20 (TimeDis (None, 30, 37, 37, 128)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_21 (TimeDis (None, 30, 18, 18, 128)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_22 (TimeDis (None, 30, 18, 18, 256)   295168    \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, 30, 18, 18, 256)   1024      \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 30, 18, 18, 256)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_25 (TimeDis (None, 30, 18, 18, 256)   590080    \n",
      "_________________________________________________________________\n",
      "time_distributed_26 (TimeDis (None, 30, 18, 18, 256)   1024      \n",
      "_________________________________________________________________\n",
      "time_distributed_27 (TimeDis (None, 30, 18, 18, 256)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_28 (TimeDis (None, 30, 9, 9, 256)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_29 (TimeDis (None, 30, 9, 9, 512)     1180160   \n",
      "_________________________________________________________________\n",
      "time_distributed_30 (TimeDis (None, 30, 9, 9, 512)     2048      \n",
      "_________________________________________________________________\n",
      "time_distributed_31 (TimeDis (None, 30, 9, 9, 512)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_32 (TimeDis (None, 30, 9, 9, 512)     2359808   \n",
      "_________________________________________________________________\n",
      "time_distributed_33 (TimeDis (None, 30, 9, 9, 512)     2048      \n",
      "_________________________________________________________________\n",
      "time_distributed_34 (TimeDis (None, 30, 9, 9, 512)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_35 (TimeDis (None, 30, 4, 4, 512)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_36 (TimeDis (None, 30, 8192)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 30, 512)           17303552  \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               295424    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 29)                3741      \n",
      "=================================================================\n",
      "Total params: 22,326,717\n",
      "Trainable params: 22,322,749\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_list = []\n",
    "\n",
    "#capturing live video frames\n",
    "model_frames_num = 30\n",
    "realtime_frames = 120\n",
    "saved_model = 'D:/College/2020/GP/Coding/GP-Code/data/checkpoints/lrcn-images.385-0.111.hdf5'\n",
    "model = load_model(saved_model, compile=False)\n",
    "# graph = tf.get_default_graph()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max frames => 300\n"
     ]
    }
   ],
   "source": [
    "data = DataSet(seq_length=model_frames_num, class_limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(frames, model):\n",
    "    assert len(frames) == model_frames_num\n",
    "#     with graph.as_default():\n",
    "    prediction = model.predict(np.expand_dims(frames, axis=0))\n",
    "    pred = data.print_class_from_prediction(np.squeeze(prediction, axis=0))\n",
    "    print(pred)\n",
    "    return pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of frames to pass before changing the frame to compare the current\n",
    "# frame against\n",
    "FRAMES_TO_PERSIST = 10\n",
    "\n",
    "# Minimum boxed area for a detected motion to count as actual motion\n",
    "# Use to filter out noise or small objects\n",
    "MIN_SIZE_FOR_MOVEMENT = 2000\n",
    "\n",
    "# Minimum length of time where no motion is detected it should take\n",
    "#(in program cycles) for the program to declare that there is no movement\n",
    "MOVEMENT_DETECTED_PERSISTENCE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create capture object\n",
    "cap = cv2.VideoCapture(5) # Flush the stream\n",
    "cap.release()\n",
    "cap = cv2.VideoCapture(\"4.mp4\") # Then start the webcam\n",
    "# Deployment\\Vid\\alaykom_2.mp4\n",
    "# Init frame variables\n",
    "first_frame = None\n",
    "next_frame = None\n",
    "\n",
    "# Init display font and timeout counters\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "delay_counter = 0\n",
    "movement_persistent_counter = 0\n",
    "\n",
    "dim = (300, 300)\n",
    "p = ''\n",
    "wait = 0\n",
    "process_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('salam', 0.29299083), ('adkhol', 0.12760317), (\"elsa'a\", 0.12377865), ('saydalya', 0.093917094), ('amel', 0.09165476)]\n",
      "[('zalan', 0.29643846), ('salam', 0.20287095), ('saydalya', 0.087403595), (\"elsa'a\", 0.081692986), ('masged', 0.06695126)]\n",
      "[('salam', 0.41637462), ('zalan', 0.11995592), ('saydalya', 0.085602105), ('amel', 0.07421346), ('adkhol', 0.069411725)]\n",
      "[('salam', 0.2753009), ('amel', 0.11391684), ('zalan', 0.11009853), ('ashrab', 0.07885848), ('adkhol', 0.07279532)]\n",
      "[('salam', 0.4982021), ('amel', 0.15268241), ('meyah', 0.05850168), (\"elsa'a\", 0.055609155), ('shokran', 0.04077679)]\n",
      "[('salam', 0.40099457), ('amel', 0.14044683), ('adkhol', 0.08079055), ('zalan', 0.07691351), ('saydalya', 0.056371767)]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-723775cb6384>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Unoccupied\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mpred_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# If there's an error in capturing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    \n",
    "    wait += 1 \n",
    "    # Set transient motion detected as false\n",
    "    transient_movement_flag = False\n",
    "    \n",
    "    # Read frame\n",
    "    ret, frame = cap.read()\n",
    "    text = \"Unoccupied\"\n",
    "    pred_frame = frame.copy()\n",
    "\n",
    "    # If there's an error in capturing\n",
    "    if not ret:\n",
    "        print(\"CAPTURE ERROR\")\n",
    "        break\n",
    "\n",
    "#     frame = cv2.flip(frame, 1)\n",
    "#     full_fram = frame.copy()\n",
    "#     full_fram = cv2.resize(frame, (800,600), interpolation = cv2.INTER_AREA)\n",
    "#     frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "#     sequence_list.append(frame)\n",
    "        \n",
    "#     if len(sequence_list) == realtime_frames:\n",
    "#         rescaledList = data.rescale_list(sequence_list, model_frames_num)\n",
    "#         p = predictions(rescaledList)\n",
    "#         sequence_list = []\n",
    "#         rescaledList = []\n",
    "        \n",
    "#     cv2.putText(full_fram, p, (250,550), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Resize and save a greyscale version of the image    \n",
    "    frame = imutils.resize(frame, width = 750)\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Blur it to remove camera noise (reducing false positives)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "    # If the first frame is nothing, initialise it\n",
    "    if first_frame is None: first_frame = gray    \n",
    "\n",
    "    delay_counter += 1\n",
    "\n",
    "    # Otherwise, set the first frame to compare as the previous frame\n",
    "    # But only if the counter reaches the appriopriate value\n",
    "    # The delay is to allow relatively slow motions to be counted as large\n",
    "    # motions if they're spread out far enough\n",
    "    if delay_counter > FRAMES_TO_PERSIST:\n",
    "        delay_counter = 0\n",
    "        first_frame = next_frame\n",
    "\n",
    "        \n",
    "    # Set the next frame to compare (the current frame)\n",
    "    next_frame = gray\n",
    "\n",
    "    # Compare the two frames, find the difference\n",
    "    frame_delta = cv2.absdiff(first_frame, next_frame)\n",
    "    thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # Fill in holes via dilate(), and find contours of the thesholds\n",
    "    thresh = cv2.dilate(thresh, None, iterations = 2)\n",
    "    cnts, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # loop over the contours\n",
    "    for c in cnts:\n",
    "\n",
    "        # Save the coordinates of all found contours\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        \n",
    "        # If the contour is too small, ignore it, otherwise, there's transient\n",
    "        # movement\n",
    "        if cv2.contourArea(c) > MIN_SIZE_FOR_MOVEMENT:\n",
    "            transient_movement_flag = True\n",
    "            \n",
    "            # Draw a rectangle around big enough movements\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # The moment something moves momentarily, reset the persistent\n",
    "    # movement timer.\n",
    "    if transient_movement_flag == True:\n",
    "        movement_persistent_flag = True\n",
    "        movement_persistent_counter = MOVEMENT_DETECTED_PERSISTENCE\n",
    "\n",
    "    # As long as there was a recent transient movement, say a movement\n",
    "    # was detected    \n",
    "    if movement_persistent_counter > 0:\n",
    "        text = \"Movement Detected \" + str(movement_persistent_counter)\n",
    "        movement_persistent_counter -= 1\n",
    "    else:\n",
    "        text = \"No Movement Detected\"\n",
    "\n",
    "# q = multiprocessing.JoinableQueue()\n",
    "\n",
    "    if wait > 30:\n",
    "        if movement_persistent_counter > 85 :\n",
    "            pred_frame = cv2.resize(pred_frame, dim, interpolation = cv2.INTER_AREA)\n",
    "            pred_frame = (pred_frame / 255.).astype(np.float32)\n",
    "            sequence_list.append(pred_frame)\n",
    "        else:\n",
    "            if len(sequence_list) > 30:\n",
    "                rescaledList = data.rescale_list(sequence_list, model_frames_num)\n",
    "                thread = threading.Thread(target = predictions, args=(rescaledList, model, ))\n",
    "                thread.daemon = True\n",
    "                thread.start()\n",
    "#                 p = predictions(rescaledList)\n",
    "                sequence_list = []\n",
    "                rescaledList = []\n",
    "\n",
    "        \n",
    "    # Print the text on the screen, and display the raw and processed video \n",
    "    # feeds\n",
    "    cv2.putText(frame, str(text), (10,35), font, 0.75, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # For if you want to show the individual video frames\n",
    "#    cv2.imshow(\"frame\", frame)\n",
    "#    cv2.imshow(\"delta\", frame_delta)\n",
    "    \n",
    "    # Convert the frame_delta to color for splicing\n",
    "    frame_delta = cv2.cvtColor(frame_delta, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Splice the two video frames together to make one long horizontal one\n",
    "    cv2.imshow(\"frame\", np.hstack((frame_delta, frame)))\n",
    "\n",
    "    # Interrupt trigger by pressing q to quit the open CV program\n",
    "    ch = cv2.waitKey(1)\n",
    "    if ch & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# Cleanup when closed\n",
    "# cv2.waitKey(0)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import threading\n",
    "# import time\n",
    "\n",
    "\n",
    "# class ThreadingExample(object):\n",
    "#     \"\"\" Threading example class\n",
    "#     The run() method will be started and it will run in the background\n",
    "#     until the application exits.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, interval=1):\n",
    "#         \"\"\" Constructor\n",
    "#         :type interval: int\n",
    "#         :param interval: Check interval, in seconds\n",
    "#         \"\"\"\n",
    "#         self.interval = interval\n",
    "\n",
    "#         thread = threading.Thread(target=self.run, args=())\n",
    "#         thread.daemon = True                            # Daemonize thread\n",
    "#         thread.start()                                  # Start the execution\n",
    "\n",
    "#     def run(self):\n",
    "#         \"\"\" Method that runs forever \"\"\"\n",
    "#         while True:\n",
    "#             # Do something\n",
    "#             print('Doing something imporant in the background')\n",
    "\n",
    "#             time.sleep(self.interval)\n",
    "\n",
    "# example = ThreadingExample()\n",
    "# time.sleep(3)\n",
    "# print('Checkpoint')\n",
    "# time.sleep(2)\n",
    "# print('Bye')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
